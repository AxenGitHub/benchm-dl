

***   p2.xlarge   ***


python 3-neon.py

2016-10-29 04:39:43,147 - neon.backends.nervanagpu - WARNING - Neon is highly optimized for Maxwell GPUs. Although you might get speedups over CPUs, note that you are running on a pre-Maxwell GPU and you might not experience the fastest performance. For faster performance using the Nervana Cloud contact info@nervanasys.com
Namespace(backend='gpu', batch_size=128, caffe=False, callback_args={'serialize': 0, 'eval_freq': None, 'progress_bar': True, 'model_file': None, 'output_file': None, 'save_path': None, 'log_token': '', 'history': 1}, compat_mode=None, config=None, data_dir='/home/ubuntu/nervana/data', datatype=<type 'numpy.float32'>, deterministic=False, device_id=0, epochs=10, eval_freq=None, history=1, log_thresh=30, log_token='', logfile=None, max_devices=1, model_file=None, no_progress_bar=False, output_file=None, progress_bar=True, rng_seed=None, rounding=False, save_path=None, serialize=0, verbose=1)
Epoch 0   [Train |████████████████████|  469/469  batches, 0.20 cost, 2.52s]
Epoch 1   [Train |████████████████████|  469/469  batches, 0.13 cost, 2.60s]
Epoch 2   [Train |████████████████████|  469/469  batches, 0.10 cost, 2.60s]
Epoch 3   [Train |████████████████████|  468/468  batches, 0.07 cost, 2.59s]
Epoch 4   [Train |████████████████████|  468/468  batches, 0.07 cost, 2.59s]
Epoch 5   [Train |████████████████████|  468/468  batches, 0.08 cost, 2.60s]
Epoch 6   [Train |████████████████████|  468/468  batches, 0.08 cost, 2.60s]
Epoch 7   [Train |████████████████████|  468/468  batches, 0.05 cost, 2.59s]
Epoch 8   [Train |████████████████████|  468/468  batches, 0.06 cost, 2.55s]
Epoch 9   [Train |████████████████████|  468/468  batches, 0.06 cost, 2.57s]
Train time: 25.8461339474 sec
Error rate: 0.949999969453 %



nvidia-smi -l 3

+------------------------------------------------------+
| NVIDIA-SMI 352.99     Driver Version: 352.99         |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 0000:00:1E.0     Off |                    0 |
| N/A   62C    P0    78W / 149W |    466MiB / 11519MiB |     56%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0       983    C   /usr/bin/python                                 64MiB |
|    0      6882    C   python                                         343MiB |
+-----------------------------------------------------------------------------+



mpstat -P ALL 3

Average:     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
Average:     all   24.99    0.00    0.11    0.00    0.00    0.06    0.00    0.00    0.00   74.85
Average:       0   99.67    0.00    0.11    0.00    0.00    0.22    0.00    0.00    0.00    0.00
Average:       1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
Average:       2    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
Average:       3    0.11    0.00    0.33    0.00    0.00    0.00    0.00    0.00    0.00   99.56




***   p2.8xlarge   ***


